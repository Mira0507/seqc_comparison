---
output: html_document
title: "Comparative analysis of Alignment/Mapping Pipelines in SEQC dataset"
author: "Mira Sohn" 
---


```{r global_options, include=FALSE}


knitr::opts_chunk$set(
    warning=FALSE,
    message=FALSE
    )


```

## Loading packages

```{r loading_packages}

library(data.table)
library(tidyverse)
library(rmarkdown)
library(ggplot2)
library(pheatmap)
library(ggrepel)
library(gridExtra)
library(AnnotationHub)
library(tximport)
library(Rsubread)
library(DESeq2)
library(seqc)
library(ensembldb)
```

## Setting AnnotationHub
### Assign your species of interest


```{r annotationhub_setup}


AnnotationSpecies <- "Homo sapiens"  # Assign your species 
ah <- AnnotationHub(hub=getAnnotationHubOption("URL"))  # Bring annotation DB

```



## Running AnnotationHub

```{r running_annotationhub}

# Set a function querying annotation
anno.fn <- function(selection, tx, gene, alias=NULL) {

    db <- query(ah, selection)
    dbName <- names(db)[length(db)]
    db <- ah[[dbName]]

# Explore with following accessors:
# columns(AnnoDb)
# keytypes(AnnoDb)
# keys(AnnoDb, keytype=..)
# select(AnnoDb, keys=.., columns=.., keytype=...)

    annokey <- keys(db, keytype=tx)

    annodb <- select(db, 
                     annokey,
                     keytype=tx,
                     columns=c(gene, "SYMBOL", alias))

    return(annodb)
}


# Filter annotation of interest
AnnoDb.en <- anno.fn("EnsDb.Hsapiens", "TXID", "GENEID")
AnnoDb.or <- anno.fn(c(AnnotationSpecies, "OrgDb"), 
                     "ENSEMBLTRANS", "ENSEMBL", alias="ALIAS")

# Explore the outputs
head(AnnoDb.en)
head(AnnoDb.or)
dim(AnnoDb.en)
dim(AnnoDb.or)

# Join two annotation tables
AnnoDb <- full_join(AnnoDb.en, AnnoDb.or, 
                    by=c("GENEID"="ENSEMBL"))

head(AnnoDb)
dim(AnnoDb)
summary(AnnoDb)
sum(is.na(AnnoDb))
sum(is.na(AnnoDb$GENEID))
sum(is.na(AnnoDb$TXID))
sum(is.na(AnnoDb$ENSEMBLTRANS))
sum(is.na(AnnoDb$SYMBOL.x))
sum(is.na(AnnoDb$SYMBOL.y))
sum(is.na(AnnoDb$ALIAS))

AnnoDb <- AnnoDb %>% 
    gather(Gene, SYMBOL, SYMBOL.x, SYMBOL.y, ALIAS) %>% 
    group_by(TXID, GENEID) %>% 
    summarize(GENE=SYMBOL) %>%
    distinct(TXID, GENEID, GENE) %>%
    na.omit()

head(AnnoDb)
dim(AnnoDb)
summary(AnnoDb)
sum(is.na(AnnoDb))
sum(is.na(AnnoDb$GENEID))
sum(is.na(AnnoDb$TXID))
sum(is.na(AnnoDb$GENE))
sum(duplicated(AnnoDb))
```


## Metadata setting

```{r generating_metadata}
# This code chunk needs to be written by yourself 

# Define sample names 
SampleNames <-  c(paste0("A", 1:3), paste0("B", 1:3)) 

# Aligner names
Aligners <- c("Salmon", "STAR", "HISAT2")

# Define group level
GroupLevel <- c("A", "B")

# Define contrast for DE analysis
Contrast <- c("Group", GroupLevel)

# Set a function for file paths
path.fn <- function(head, tail) { 

    vec <- c(paste0(head,    # head = e.g. "hisat2", "star", or "salmon"
                    "_output/",
                    SampleNames,
                    tail))   # tail = file name after SampleNames 
}


# Define .sf file path
sf <- path.fn("salmon",".salmon_quant/quant.sf")


# Define STAR file path
star <- path.fn("star", "Aligned.sortedByCoord.out.bam")

# Define HISAT2 file path
hisat <- path.fn("hisat2", ".sorted.bam")


# Define sample groups
group <- c(rep("A", 3), rep("B", 3))

# Create metadata
metadata <- data.frame(Sample=factor(SampleNames, levels=SampleNames),
                       Group=factor(group, levels=GroupLevel),
                       Salmon_path=sf,
                       STAR_path=star, 
                       HISAT2_path=hisat)

# Assign row names with sample names
rownames(metadata) <- SampleNames


# Explore the metadata
print(metadata)


```


## Importing the SEQC qPCR dataset 

### Used a dataset provided by [**seqc**](http://bioconductor.org/packages/release/data/experiment/html/seqc.html) package in bioconductor 

```{r importing_seqc}

# Create a character vector assigning column names 
mycol <- c("Symbol", paste0(SampleNames, "_value"))

# Slice the taqman data frame only for genes and the assigned SampleNames (A1-A3, B1-B3)
seqc <- taqman[, colnames(taqman) %in% mycol]

# Explore the sliced taqman qPCR data 
head(seqc)
dim(seqc)
sum(is.na(seqc))


# Add annotation to the qPCR dataset
seqc <- right_join(AnnoDb, 
                   seqc,
                   by=c("GENE"="Symbol")) # Explore seqc


head(seqc)
dim(seqc)
summary(seqc)
sum(duplicated(seqc))
sum(is.na(seqc))
sum(is.na(seqc$TXID))
sum(is.na(seqc$GENEID))
sum(is.na(seqc$GENE))

seqc[is.na(seqc$TXID),] %>% print(n=155) 




```




## featureCounts parameter setting

```{r featurecounts_parameters}

# "mm10", "mm9", "hg38", or "hg19"
annot.inbuilt <- "hg38" 

# GTF file path
annot.ext <- "reference_GENCODE/gencode.v36.primary_assembly.annotation.gtf"

# annotation type:
# e.g.: "gene_id", "transcript_id", or "gene_name"
GTF.attrType <- "gene_id"

# Number of cores 
nthread <- 16 

# Set a function importing counts from BAM files with featureCounts()
fcounts.fn <- function(vec) {

    fc <- featureCounts(files=vec,   # a vector assigning BAM file paths
                         annot.inbuilt=annot.inbuilt,
                         annot.ext=annot.ext,
                         GTF.attrType=GTF.attrType,
                         isGTFAnnotationFile=T,
                         nthread=nthread, 
                         isPairedEnd=T,  
                         verbose=T)

    return(fc$counts)
}


```

## Importing counts 

### Importing Salmon counts

#### Note:     

#### txi1 <- tximport(..., txOut=F)   
#### txi2 <- tximport(..., txOut=T)     
#### txi2 <- summarizedToGene(...)    

#### counts extracted from txi1 and txi2 are the same 


```{r import_salmon}

# Import gene level summarized counts 
salmon.txi <- tximport(metadata$Salmon_path, 
                       type = "salmon", 
                       tx2gene=AnnoDb[, 1:2],   # Annotate at gene level (ENSEMBL)
                       ignoreTxVersion=T) 

# Extract the counts and save as a data frame
salmon.counts <- salmon.txi$counts

# Explore the salmon count data frame
head(salmon.counts)
dim(salmon.counts)
summary(salmon.counts)

```

### Importing STAR counts


```{r import_star}

# Extract counts by running featureCounts() 
star.counts <- fcounts.fn(metadata$STAR_path)


# Explore the STAR count data frame
head(star.counts)
dim(star.counts)
summary(star.counts)

```


### Importing HISAT2 counts

```{r import_hisat2}

# Extract counts by running featureCounts() 
hisat2.counts <- fcounts.fn(metadata$HISAT2_path)

# Explore the HISAT2 count data frame
head(hisat2.counts)
dim(hisat2.counts)
summary(hisat2.counts)

```

## Data cleaning: sample and gene annotation


```{r count_dataframe_cleaning}

countList <- list(salmon.counts, 
                  star.counts,
                  hisat2.counts)

# Assign names of the count data frames in the count list
names(countList) <- Aligners

# Set a function cleaning the count data frame
clean.fn <- function(df) {

    # Convert to a data frame
    df <- as.data.frame(df)

    # Assign column names
    names(df) <- SampleNames

    # Bring row names to a column
    df <- df %>% rownames_to_column(var="GENEID")

    return(df)
}

clean.annotation.fn <- function(df) {

    # Re-annotate without version specification
    df <- separate(df, "GENEID", c("GENEID", "Version"))
    df <- df[, colnames(df) != "Version"]

    return(df)
}




# Clean the count data frames
for (x in Aligners) {

    countList[[x]] <- clean.fn(countList[[x]])

    if (x %in% Aligners[2:3]) {

        countList[[x]] <- clean.annotation.fn(countList[[x]])
}

   
    # Remove duplicated rows
    countList[[x]] <- distinct(countList[[x]], 
                               GENEID, A1, A2, A3, B1, B2, B3)

}



# Explore the cleaned count data frames 
head(countList[[1]])
head(countList[[2]])
head(countList[[3]])
dim(countList[[1]])
dim(countList[[2]])
dim(countList[[3]])
sum(duplicated(countList[[1]]))
sum(duplicated(countList[[2]]))
sum(duplicated(countList[[3]]))


# Convert Salmon counts to integers 
countList[["Salmon"]] <- cbind(GENEID=countList[["Salmon"]][, "GENEID"],
                               round(countList[["Salmon"]][, 
                               colnames(countList[["Salmon"]]) %in% SampleNames]))

# Explore the cleaned count data frames 
head(countList[[1]])


```

## Subsetting genes in the count datasets



```{r subsetting_genesI}

subList <- countList

for (x in Aligners) {

    table <- subList[[x]]
    subList[[x]] <- table[table$GENEID %in% seqc$GENEID,]
    

}

# Explore the cleaned count data frames 
head(subList[[1]])
head(subList[[2]])
head(subList[[3]])
dim(subList[[1]])
dim(subList[[2]])
dim(subList[[3]])



```


## Subsetting genes in the qPCR dataset


```{r subsetting_genesII}

# Count the number of gene id from the qPCR data set in the count data
sum(seqc$GENEID %in% subList[[1]]$GENEID)

# Remove the transcript id column 
sub.seqc <- seqc[seqc$GENEID %in% subList[[1]]$GENEID,][, colnames(seqc) != "TXID"]

# Count the number of duplocated rows
sum(duplicated(sub.seqc))


# Filter out the duplicated rows
sub.seqc <- distinct(sub.seqc)

# Explore the cleaned data 
head(sub.seqc)
dim(sub.seqc)
sum(is.na(sub.seqc))

```

## Plotting sequencing depth 

```{r library_size}

# Set a function generating a data frame with sequencing depth
seq.depth.fn <- function(df, aligner) {

    seqdf <- as.data.frame(colSums(df[, SampleNames])) %>% 
        rownames_to_column (var="Sample") %>% 
        mutate(Aligner=aligner)

    names(seqdf) <- c("Sample", "Count", "Aligner")

    return(seqdf)
}

# Set a function for a bar plot comparing values
comparing.barplot.fn <- function(df, yval, title, ytitle) {

    ggplot(df, 
       aes(x=Sample, y=yval, group=Aligner, fill=Aligner)) +
    geom_bar(stat="identity", position="dodge", color="black") +
    theme_bw() +
    ggtitle(title) + 
    ylab(ytitle)

}







# Initialize the seq depth data frame with the first aligner
seq.depth.df <- seq.depth.fn(countList[[1]], Aligners[1])

# Extend the seq depth data frame with the rest of aligners
for (x in Aligners) {

    if (x %in% Aligners[2:length(Aligners)]) {

        seq.depth.df <- rbind(seq.depth.df, 
                              seq.depth.fn(countList[[x]], x))
    }
}

# Explore how the data frame 
print(seq.depth.df)
summary(seq.depth.df)

# Convert character vectors to factors
seq.depth.df$Sample <- factor(seq.depth.df$Sample, 
                              levels=SampleNames)
seq.depth.df$Aligner <- factor(seq.depth.df$Aligner, 
                               levels=Aligners)

# Create a plot presenting sequencing depth
comparing.barplot.fn(seq.depth.df, 
                     seq.depth.df$Count, 
                     "Sequencing Depth by Sample and Aligner", 
                     "Count")

```

## Generating DESeq2 objects


```{r generating_deseq2_objects}

# Initialize new lists for storing dds objects
ddsList <- subList
vsdList <- subList


for (x in Aligners) {

    m <- countList[[x]][, colnames(subList[[x]]) != "GENEID"] %>% as.matrix()
    rownames(m) <- countList[[x]]$GENEID

    ddsList[[x]] <- DESeqDataSetFromMatrix(m, 
                                           colData=metadata, 
                                           design=~Group) 

    vsdList[[x]] <- varianceStabilizingTransformation(ddsList[[x]], 
                                                      blind=TRUE) 
}

# Explore generated objects
summary(ddsList)
summary(vsdList)


```


## Estimating size factors


```{r size_factors}

# Calculate and add size factors to the DEseq object
for (x in Aligners) {

    ddsList[[x]] <- estimateSizeFactors(ddsList[[x]])

}

# Set a function summarizing size factors by aligner to a data frame
sfactor.fn <- function(df, aligner) {

    sizefactor <- as.data.frame(round(sizeFactors(df), 3)) %>%
        rownames_to_column(var="Sample") %>%
        mutate(Aligner=aligner)

    names(sizefactor) <- c("Sample", "Size_Factor", "Aligner")

    return(sizefactor)

}

# Initialize a data frame with the first aligner 
size.factor.df <- sfactor.fn(ddsList[[1]], Aligners[1])


for (x in Aligners) {

    if (x != Aligners[1]) {

        size.factor.df <- rbind(size.factor.df, 
                                sfactor.fn(ddsList[[x]], x))
    }
}


# Explore the data frame
print(size.factor.df)

# Convert character vectors to factors
size.factor.df$Sample <- factor(size.factor.df$Sample, 
                              levels=SampleNames)
size.factor.df$Aligner <- factor(size.factor.df$Aligner, 
                               levels=Aligners)

# Plot calculated size factors
comparing.barplot.fn(size.factor.df, 
                     size.factor.df$Size_Factor,  
                     "Size Factors by Aligner and Sample", 
                     "Size Factor")

```


## Estimating dispersion and Wald test

```{r dispersion_waldtest}

for (x in Aligners) {

    # Dispersion
    ddsList[[x]] <- estimateDispersions(ddsList[[x]])
    
    # Wald test
    ddsList[[x]] <- nbinomWaldTest(ddsList[[x]])

}


# Explore generated data in the dds object 
ddsList[[1]]

```

## Sample QC: Principal Component Analysis 

```{r QC_PCA}

# Assigne what to compare
GroupOfInterest <- Contrast[1]


# Set a function for sample pca
qcpca.fn <- function(obj, title) {

    plotPCA(obj,
        intgroup=GroupOfInterest,
        returnData=FALSE) + theme_bw() + ggtitle(paste("PCA:", title)) 

}

# Print the plots
qcpca.fn(vsdList[[1]], Aligners[1]) 
qcpca.fn(vsdList[[2]], Aligners[2])
qcpca.fn(vsdList[[3]], Aligners[3]) 




```

## Sample QC: Sample Correlation Heatmap

```{r QC_correlation_heatmap}

# Heatmap annotation
HeatmapAnno <- metadata[, c("Sample", "Group")]

# Set a function generating a correlation heatmap
cheatmap.fn <- function(df, title) {

    # Extract a normalized count matrix
    vm <- assay(df)

    # Generate a correlation matrix
    cm <- cor(vm)

    # Generate a heatmap
    pheatmap(cm, 
             annotation=HeatmapAnno, 
             main=paste("Sample Correlation Heatmap:", title))
}


# Print the heatmaps
cheatmap.fn(vsdList[[1]], Aligners[1])
cheatmap.fn(vsdList[[2]], Aligners[2])
cheatmap.fn(vsdList[[3]], Aligners[3])

```

## Running DE analysis


```{r DE_analysis}



# Run DESeq 
for (x in Aligners) {

    ddsList[[x]] <- DESeq(ddsList[[x]])
    # Check result names 
    ResNames <- resultsNames(ddsList[[x]])
    print(ResNames)

}


```

## Creating a dispersion plot

```{r dispersion_plot}

# Set a function plotting dispersion
dplot.fn <- function(dds, title) {

    plotDispEsts(dds, 
                 main=paste("Dispersion over Counts:", title))
}

# Plot dispersion patterns
dplot.fn(ddsList[[1]], Aligners[1])
dplot.fn(ddsList[[2]], Aligners[2])
dplot.fn(ddsList[[3]], Aligners[3])

# Do they fit well with the DESeq2 estimation model?

```

## Setting how to extract fold-change results
### Change variables below

```{r setting_resultcondition}

# Set FDR threshold alpha
alpha=0.1

# Set the coefficients to compare 
Coef <- ResNames[-1]
print(Coef) 





# Set a function to clean a result table 
lfctable.fn <- function(df) {
    df <- df %>% 
        rownames_to_column(var="GENEID") %>%
        mutate(FDR=ifelse(padj < 0.1 & !is.na(padj), 
                                   "< 0.1", 
                                   "> 0.1")) 
    return(df)
}

# Set a function extracting results
extract.lfc.fn <- function(dds) {

    res <- results(dds, contrast=Contrast, alpha=alpha)
    lfctable.fn(as.data.frame(res))

    return(lfctable.fn(as.data.frame(res)))


}

```


## Extracting log2FoldChanges
### You can change alpha depending on your interest of FDR level



```{r DEresult_extraction}

# Initialize a list storing lfc data frames
lfcList <- countList

# Extract DE results
# The Contrast variable was defined in the previous chunk
# Extraction with no shrinkage
# alpha: FDR threshold
for (x in Aligners) {

    lfcList[[x]] <- extract.lfc.fn(ddsList[[x]])

    print(head(lfcList[[x]]))

}



```



## Exploring distribution of false discovery rate (FDR)

```{r FDR_distribution}

# Initialize a data frame for FDR with the first lfc data frame
fdr.df <- data.frame(Aligner=Aligners[1], 
                     FDR=lfcList[[1]]$padj)

# Extract FDRs from each result data frame
for (x in Aligners) {

    if (x != Aligners[1]) {

        afdr <- data.frame(Aligner=x, 
                           FDR=lfcList[[x]]$padj)

        fdr.df <- rbind(fdr.df, afdr)

    }
}


# Explore the output FDR data frame
head(fdr.df)

# Convert character variables to factors
fdr.df$Aligner <- factor(fdr.df$Aligner, levels=Aligners)

# Plot distribution of FDR 
ggplot(fdr.df, 
       aes(x=FDR, y=..count.., color=Aligner)) + 
    geom_density() + 
    theme_bw() + 
    scale_x_log10() + 
    ggtitle("Distribution of False Discovery Rate (FDR) by Aligner") + 
    ylab("Count")

```

## Presenting distribution of log2FoldChange

### Black: total genes (padj =/= NA)
### Colored: genes above or below FDR=0.1


```{r L2FC_distribution}

# Initialize a data frame storing lfc values
ldist.df <- data.frame(Aligner=Aligners[1], 
                       LFC=subset(lfcList[[1]], FDR == "< 0.1")$log2FoldChange)

# Extract lfc values from each result data frame
for (x in Aligners) {

    if (x != Aligners[1]) {

        ld <- data.frame(Aligner=x,
                         LFC=subset(lfcList[[x]], 
                                    FDR == "< 0.1")$log2FoldChange)

        ldist.df <- rbind(ldist.df, ld)

    }

}

# Explore the output data frame
head(ldist.df)

# Convert character variables to factors
ldist.df$Aligner <- factor(ldist.df$Aligner, levels=Aligners)

# Plot distribution of log2FoldChange by aligner
ggplot(ldist.df,
       aes(x=LFC,
           y=..count.., 
           color=Aligner)) +
geom_density() + 
theme_bw() + 
geom_vline(xintercept=c(-1, 1), 
           linetype="dashed", color="black", size=0.5) + 
ggtitle("Distribution of log2FoldChange Values by Aligner (FDR < 0.1)") +
ylab("Count")



```


## Exploring mean-difference with an MA plot


## Session Info

```{r session_info}

sessionInfo()

```

